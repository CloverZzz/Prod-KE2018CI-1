{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR - 10\n",
    "## Improved CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/cifar10_plot.png\"\n",
    "     style=\"float: left; margin-right: 1px;\" width=\"500\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_class_names, get_train_data, get_test_data, plot_images\n",
    "from helper import plot_model, predict_classes, visualize_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change matplotlib graph style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding file: data/batches.meta\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "class_names = get_class_names()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hight and width of the images\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "# 3 channels, Red, Green and Blue\n",
    "CHANNELS = 3\n",
    "\n",
    "# Number of epochs\n",
    "NUM_EPOCH = 350\n",
    "# NUM_EPOCH = 10\n",
    "\n",
    "# learning rate\n",
    "LEARN_RATE = 1.0e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and decode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset. Labels are integers whereas class is one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding file: data/data_batch_1\n",
      "Decoding file: data/data_batch_2\n",
      "Decoding file: data/data_batch_3\n",
      "Decoding file: data/data_batch_4\n",
      "Decoding file: data/data_batch_5\n"
     ]
    }
   ],
   "source": [
    "images_train, labels_train, class_train = get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding file: data/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_test, labels_test, class_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:\t 50000\n",
      "Testing set size:\t 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\\t\",len(images_train))\n",
    "print(\"Testing set size:\\t\",len(images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset has been loaded and consists of a total of 60,000 images and corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a better CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pure CNN model from https://arxiv.org/pdf/1412.6806.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_cnn_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNELS)))    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))  \n",
    "    model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))    \n",
    "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
    "    model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))    \n",
    "    model.add(Dropout(0.5))    \n",
    "    \n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (1, 1),padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(10, (1, 1), padding='valid'))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = pure_cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model_improved.h5',  # model filename\n",
    "                             monitor='val_loss', # quantity to monitor\n",
    "                             verbose=0, # verbosity - 0 or 1\n",
    "                             save_best_only= True, # The latest best model will not be overwritten\n",
    "                             mode='auto') # The decision to overwrite model is made \n",
    "                                          # automatically depending on the quantity to monitor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
    "              optimizer=Adam(lr=LEARN_RATE), # Adam optimizer with 1.0e-4 learning rate\n",
    "              metrics = ['accuracy']) # Metrics to be evaluated by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on categorical cross entropy loss function see - https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on the data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/350\n",
      "50000/50000 [==============================] - 98s - loss: 2.0037 - acc: 0.2386 - val_loss: 1.7904 - val_acc: 0.3380\n",
      "Epoch 2/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.6934 - acc: 0.3677 - val_loss: 1.5696 - val_acc: 0.4191\n",
      "Epoch 3/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.5705 - acc: 0.4210 - val_loss: 1.4926 - val_acc: 0.4473\n",
      "Epoch 4/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.4949 - acc: 0.4522 - val_loss: 1.4401 - val_acc: 0.4751\n",
      "Epoch 5/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.4287 - acc: 0.4751 - val_loss: 1.3591 - val_acc: 0.5017\n",
      "Epoch 6/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.3833 - acc: 0.4939 - val_loss: 1.3112 - val_acc: 0.5265\n",
      "Epoch 7/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.3235 - acc: 0.5234 - val_loss: 1.2849 - val_acc: 0.5385\n",
      "Epoch 8/350\n",
      "50000/50000 [==============================] - 95s - loss: 1.2766 - acc: 0.5385 - val_loss: 1.2178 - val_acc: 0.5651\n",
      "Epoch 9/350\n",
      "50000/50000 [==============================] - 98s - loss: 1.2301 - acc: 0.5593 - val_loss: 1.1645 - val_acc: 0.5841\n",
      "Epoch 10/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.1993 - acc: 0.5701 - val_loss: 1.1179 - val_acc: 0.6019\n",
      "Epoch 11/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.1690 - acc: 0.5822 - val_loss: 1.1427 - val_acc: 0.5933\n",
      "Epoch 12/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.1354 - acc: 0.5934 - val_loss: 1.1038 - val_acc: 0.6082\n",
      "Epoch 13/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.1117 - acc: 0.6034 - val_loss: 1.0734 - val_acc: 0.6193\n",
      "Epoch 14/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.0907 - acc: 0.6100 - val_loss: 1.0481 - val_acc: 0.6322\n",
      "Epoch 15/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.0658 - acc: 0.6208 - val_loss: 1.0457 - val_acc: 0.6290\n",
      "Epoch 16/350\n",
      "50000/50000 [==============================] - 94s - loss: 1.0451 - acc: 0.6296 - val_loss: 1.0067 - val_acc: 0.6399\n",
      "Epoch 17/350\n",
      "50000/50000 [==============================] - 108s - loss: 1.0276 - acc: 0.6362 - val_loss: 0.9880 - val_acc: 0.6504\n",
      "Epoch 18/350\n",
      "50000/50000 [==============================] - 97s - loss: 1.0046 - acc: 0.6442 - val_loss: 0.9987 - val_acc: 0.6429\n",
      "Epoch 19/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.9886 - acc: 0.6494 - val_loss: 0.9551 - val_acc: 0.6614\n",
      "Epoch 20/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.9671 - acc: 0.6592 - val_loss: 0.9609 - val_acc: 0.6633\n",
      "Epoch 21/350\n",
      "50000/50000 [==============================] - 95s - loss: 0.9534 - acc: 0.6620 - val_loss: 0.9475 - val_acc: 0.6617\n",
      "Epoch 22/350\n",
      "50000/50000 [==============================] - 107s - loss: 0.9365 - acc: 0.6689 - val_loss: 0.9095 - val_acc: 0.6790\n",
      "Epoch 23/350\n",
      "50000/50000 [==============================] - 119s - loss: 0.9200 - acc: 0.6765 - val_loss: 0.9046 - val_acc: 0.6819\n",
      "Epoch 24/350\n",
      "50000/50000 [==============================] - 121s - loss: 0.9035 - acc: 0.6828 - val_loss: 0.9419 - val_acc: 0.6698\n",
      "Epoch 25/350\n",
      "50000/50000 [==============================] - 117s - loss: 0.8854 - acc: 0.6907 - val_loss: 0.8742 - val_acc: 0.6911\n",
      "Epoch 26/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.8725 - acc: 0.6928 - val_loss: 0.8553 - val_acc: 0.6987\n",
      "Epoch 27/350\n",
      "50000/50000 [==============================] - 95s - loss: 0.8600 - acc: 0.6971 - val_loss: 0.8526 - val_acc: 0.6945\n",
      "Epoch 28/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.8519 - acc: 0.7019 - val_loss: 0.8521 - val_acc: 0.6992\n",
      "Epoch 29/350\n",
      "50000/50000 [==============================] - 112s - loss: 0.8399 - acc: 0.7046 - val_loss: 0.8380 - val_acc: 0.7043\n",
      "Epoch 30/350\n",
      "50000/50000 [==============================] - 95s - loss: 0.8279 - acc: 0.7090 - val_loss: 0.8240 - val_acc: 0.7122\n",
      "Epoch 31/350\n",
      "50000/50000 [==============================] - 108s - loss: 0.8136 - acc: 0.7122 - val_loss: 0.8182 - val_acc: 0.7129\n",
      "Epoch 32/350\n",
      "50000/50000 [==============================] - 96s - loss: 0.8001 - acc: 0.7204 - val_loss: 0.8046 - val_acc: 0.7200\n",
      "Epoch 33/350\n",
      "50000/50000 [==============================] - 109s - loss: 0.7925 - acc: 0.7222 - val_loss: 0.7867 - val_acc: 0.7273\n",
      "Epoch 34/350\n",
      "50000/50000 [==============================] - 101s - loss: 0.7793 - acc: 0.7264 - val_loss: 0.8261 - val_acc: 0.7128\n",
      "Epoch 35/350\n",
      "50000/50000 [==============================] - 97s - loss: 0.7740 - acc: 0.7277 - val_loss: 0.7876 - val_acc: 0.7262\n",
      "Epoch 36/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.7607 - acc: 0.7334 - val_loss: 0.7861 - val_acc: 0.7244\n",
      "Epoch 37/350\n",
      "50000/50000 [==============================] - 97s - loss: 0.7488 - acc: 0.7360 - val_loss: 0.7888 - val_acc: 0.7286\n",
      "Epoch 38/350\n",
      "50000/50000 [==============================] - 108s - loss: 0.7387 - acc: 0.7429 - val_loss: 0.7603 - val_acc: 0.7332\n",
      "Epoch 39/350\n",
      "50000/50000 [==============================] - 108s - loss: 0.7331 - acc: 0.7435 - val_loss: 0.7926 - val_acc: 0.7246\n",
      "Epoch 40/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.7231 - acc: 0.7465 - val_loss: 0.7402 - val_acc: 0.7441\n",
      "Epoch 41/350\n",
      "50000/50000 [==============================] - 126s - loss: 0.7117 - acc: 0.7510 - val_loss: 0.7342 - val_acc: 0.7418\n",
      "Epoch 42/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.7069 - acc: 0.7533 - val_loss: 0.7456 - val_acc: 0.7407\n",
      "Epoch 43/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.7050 - acc: 0.7521 - val_loss: 0.7537 - val_acc: 0.7341\n",
      "Epoch 44/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6874 - acc: 0.7598 - val_loss: 0.7234 - val_acc: 0.7472\n",
      "Epoch 45/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6829 - acc: 0.7606 - val_loss: 0.7165 - val_acc: 0.7476\n",
      "Epoch 46/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6760 - acc: 0.7632 - val_loss: 0.7659 - val_acc: 0.7320\n",
      "Epoch 47/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6647 - acc: 0.7658 - val_loss: 0.7105 - val_acc: 0.7529\n",
      "Epoch 48/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6572 - acc: 0.7684 - val_loss: 0.7000 - val_acc: 0.7513\n",
      "Epoch 49/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6521 - acc: 0.7718 - val_loss: 0.7038 - val_acc: 0.7578\n",
      "Epoch 50/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6485 - acc: 0.7735 - val_loss: 0.6829 - val_acc: 0.7579\n",
      "Epoch 51/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6350 - acc: 0.7776 - val_loss: 0.7201 - val_acc: 0.7505\n",
      "Epoch 52/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6268 - acc: 0.7799 - val_loss: 0.7024 - val_acc: 0.7570\n",
      "Epoch 53/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6230 - acc: 0.7814 - val_loss: 0.6760 - val_acc: 0.7651\n",
      "Epoch 54/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6205 - acc: 0.7831 - val_loss: 0.7207 - val_acc: 0.7494\n",
      "Epoch 55/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6056 - acc: 0.7875 - val_loss: 0.7055 - val_acc: 0.7576\n",
      "Epoch 56/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.6033 - acc: 0.7873 - val_loss: 0.6721 - val_acc: 0.7642\n",
      "Epoch 57/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.5943 - acc: 0.7905 - val_loss: 0.6629 - val_acc: 0.7689\n",
      "Epoch 58/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.5886 - acc: 0.7926 - val_loss: 0.6527 - val_acc: 0.7700\n",
      "Epoch 59/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.5805 - acc: 0.7998 - val_loss: 0.6808 - val_acc: 0.7690\n",
      "Epoch 60/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.5758 - acc: 0.7965 - val_loss: 0.6792 - val_acc: 0.7638\n",
      "Epoch 61/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.5648 - acc: 0.8012 - val_loss: 0.6543 - val_acc: 0.7724\n",
      "Epoch 62/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.5694 - acc: 0.7997 - val_loss: 0.6536 - val_acc: 0.7737\n",
      "Epoch 63/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 125s - loss: 0.5590 - acc: 0.8057 - val_loss: 0.6486 - val_acc: 0.7766\n",
      "Epoch 64/350\n",
      "50000/50000 [==============================] - 99s - loss: 0.5498 - acc: 0.8055 - val_loss: 0.6380 - val_acc: 0.7752\n",
      "Epoch 65/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5485 - acc: 0.8078 - val_loss: 0.6227 - val_acc: 0.7822\n",
      "Epoch 66/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5410 - acc: 0.8088 - val_loss: 0.6332 - val_acc: 0.7781\n",
      "Epoch 67/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5329 - acc: 0.8119 - val_loss: 0.6475 - val_acc: 0.7772\n",
      "Epoch 68/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5282 - acc: 0.8153 - val_loss: 0.6331 - val_acc: 0.7796\n",
      "Epoch 69/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5202 - acc: 0.8169 - val_loss: 0.6216 - val_acc: 0.7891\n",
      "Epoch 70/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5192 - acc: 0.8160 - val_loss: 0.6578 - val_acc: 0.7736\n",
      "Epoch 71/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5176 - acc: 0.8179 - val_loss: 0.6102 - val_acc: 0.7899\n",
      "Epoch 72/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.5023 - acc: 0.8233 - val_loss: 0.6708 - val_acc: 0.7715\n",
      "Epoch 73/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4982 - acc: 0.8252 - val_loss: 0.6154 - val_acc: 0.7891\n",
      "Epoch 74/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4946 - acc: 0.8247 - val_loss: 0.6263 - val_acc: 0.7873\n",
      "Epoch 75/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4905 - acc: 0.8270 - val_loss: 0.6316 - val_acc: 0.7824\n",
      "Epoch 76/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4858 - acc: 0.8284 - val_loss: 0.6135 - val_acc: 0.7879\n",
      "Epoch 77/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4760 - acc: 0.8327 - val_loss: 0.6026 - val_acc: 0.7921\n",
      "Epoch 78/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4770 - acc: 0.8311 - val_loss: 0.6264 - val_acc: 0.7873\n",
      "Epoch 79/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4686 - acc: 0.8345 - val_loss: 0.6038 - val_acc: 0.7952\n",
      "Epoch 80/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4618 - acc: 0.8371 - val_loss: 0.6083 - val_acc: 0.7954\n",
      "Epoch 81/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4570 - acc: 0.8387 - val_loss: 0.6350 - val_acc: 0.7860\n",
      "Epoch 82/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4586 - acc: 0.8374 - val_loss: 0.6250 - val_acc: 0.7935\n",
      "Epoch 83/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4511 - acc: 0.8424 - val_loss: 0.6146 - val_acc: 0.7926\n",
      "Epoch 84/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4507 - acc: 0.8417 - val_loss: 0.6157 - val_acc: 0.7908\n",
      "Epoch 85/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4381 - acc: 0.8436 - val_loss: 0.6101 - val_acc: 0.7989\n",
      "Epoch 86/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4366 - acc: 0.8446 - val_loss: 0.5865 - val_acc: 0.7975\n",
      "Epoch 87/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4308 - acc: 0.8476 - val_loss: 0.5916 - val_acc: 0.8028\n",
      "Epoch 88/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4250 - acc: 0.8503 - val_loss: 0.5969 - val_acc: 0.8012\n",
      "Epoch 89/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4205 - acc: 0.8521 - val_loss: 0.6082 - val_acc: 0.7985\n",
      "Epoch 90/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4189 - acc: 0.8517 - val_loss: 0.6293 - val_acc: 0.7886\n",
      "Epoch 91/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4185 - acc: 0.8514 - val_loss: 0.6147 - val_acc: 0.7918\n",
      "Epoch 92/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4110 - acc: 0.8535 - val_loss: 0.5929 - val_acc: 0.7979\n",
      "Epoch 93/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4012 - acc: 0.8569 - val_loss: 0.5919 - val_acc: 0.8002\n",
      "Epoch 94/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.4055 - acc: 0.8553 - val_loss: 0.5762 - val_acc: 0.8050\n",
      "Epoch 95/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.3994 - acc: 0.8585 - val_loss: 0.5876 - val_acc: 0.8048\n",
      "Epoch 96/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.3910 - acc: 0.8610 - val_loss: 0.6625 - val_acc: 0.7834\n",
      "Epoch 97/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.3890 - acc: 0.8621 - val_loss: 0.5838 - val_acc: 0.8071\n",
      "Epoch 98/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.3889 - acc: 0.8613 - val_loss: 0.6017 - val_acc: 0.8048\n",
      "Epoch 99/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.3818 - acc: 0.8639 - val_loss: 0.5890 - val_acc: 0.8082\n",
      "Epoch 100/350\n",
      "50000/50000 [==============================] - 96s - loss: 0.3733 - acc: 0.8667 - val_loss: 0.5867 - val_acc: 0.8113\n",
      "Epoch 101/350\n",
      "50000/50000 [==============================] - 113s - loss: 0.3713 - acc: 0.8669 - val_loss: 0.6038 - val_acc: 0.8036\n",
      "Epoch 102/350\n",
      "50000/50000 [==============================] - 112s - loss: 0.3710 - acc: 0.8681 - val_loss: 0.5840 - val_acc: 0.8102\n",
      "Epoch 103/350\n",
      "50000/50000 [==============================] - 112s - loss: 0.3681 - acc: 0.8684 - val_loss: 0.5886 - val_acc: 0.8064\n",
      "Epoch 104/350\n",
      "50000/50000 [==============================] - 115s - loss: 0.3623 - acc: 0.8705 - val_loss: 0.5944 - val_acc: 0.8130\n",
      "Epoch 105/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3569 - acc: 0.8747 - val_loss: 0.5856 - val_acc: 0.8109\n",
      "Epoch 106/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3542 - acc: 0.8754 - val_loss: 0.5857 - val_acc: 0.8096\n",
      "Epoch 107/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3518 - acc: 0.8746 - val_loss: 0.5842 - val_acc: 0.8100\n",
      "Epoch 108/350\n",
      "50000/50000 [==============================] - 119s - loss: 0.3455 - acc: 0.8778 - val_loss: 0.5988 - val_acc: 0.8069\n",
      "Epoch 109/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3446 - acc: 0.8771 - val_loss: 0.5668 - val_acc: 0.8173\n",
      "Epoch 110/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3416 - acc: 0.8792 - val_loss: 0.5933 - val_acc: 0.8087\n",
      "Epoch 111/350\n",
      "50000/50000 [==============================] - 120s - loss: 0.3346 - acc: 0.8801 - val_loss: 0.6166 - val_acc: 0.8064\n",
      "Epoch 112/350\n",
      "50000/50000 [==============================] - 122s - loss: 0.3370 - acc: 0.8787 - val_loss: 0.5782 - val_acc: 0.8147\n",
      "Epoch 113/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3293 - acc: 0.8837 - val_loss: 0.5789 - val_acc: 0.8180\n",
      "Epoch 114/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3244 - acc: 0.8832 - val_loss: 0.5766 - val_acc: 0.8149\n",
      "Epoch 115/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3271 - acc: 0.8834 - val_loss: 0.5972 - val_acc: 0.8112\n",
      "Epoch 116/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.3240 - acc: 0.8838 - val_loss: 0.5904 - val_acc: 0.8173\n",
      "Epoch 117/350\n",
      "50000/50000 [==============================] - 123s - loss: 0.3151 - acc: 0.8874 - val_loss: 0.5930 - val_acc: 0.8137\n",
      "Epoch 118/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3148 - acc: 0.8863 - val_loss: 0.5642 - val_acc: 0.8173\n",
      "Epoch 119/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3109 - acc: 0.8880 - val_loss: 0.5774 - val_acc: 0.8187\n",
      "Epoch 120/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3058 - acc: 0.8898 - val_loss: 0.5635 - val_acc: 0.8206\n",
      "Epoch 121/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.3019 - acc: 0.8912 - val_loss: 0.5924 - val_acc: 0.8155\n",
      "Epoch 122/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.3030 - acc: 0.8905 - val_loss: 0.6072 - val_acc: 0.8113\n",
      "Epoch 123/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2992 - acc: 0.8932 - val_loss: 0.6050 - val_acc: 0.8122\n",
      "Epoch 124/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2946 - acc: 0.8957 - val_loss: 0.5803 - val_acc: 0.8230\n",
      "Epoch 125/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 125s - loss: 0.2924 - acc: 0.8947 - val_loss: 0.6004 - val_acc: 0.8132\n",
      "Epoch 126/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2907 - acc: 0.8954 - val_loss: 0.5895 - val_acc: 0.8196\n",
      "Epoch 127/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2875 - acc: 0.8969 - val_loss: 0.5869 - val_acc: 0.8216\n",
      "Epoch 128/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2830 - acc: 0.8978 - val_loss: 0.5996 - val_acc: 0.8154\n",
      "Epoch 129/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2804 - acc: 0.9008 - val_loss: 0.5704 - val_acc: 0.8196\n",
      "Epoch 130/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2837 - acc: 0.8979 - val_loss: 0.5844 - val_acc: 0.8189\n",
      "Epoch 131/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2783 - acc: 0.9010 - val_loss: 0.5938 - val_acc: 0.8224\n",
      "Epoch 132/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2708 - acc: 0.9025 - val_loss: 0.5879 - val_acc: 0.8186\n",
      "Epoch 133/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2686 - acc: 0.9043 - val_loss: 0.5868 - val_acc: 0.8182\n",
      "Epoch 134/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2697 - acc: 0.9030 - val_loss: 0.6060 - val_acc: 0.8183\n",
      "Epoch 135/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2661 - acc: 0.9041 - val_loss: 0.5771 - val_acc: 0.8272\n",
      "Epoch 136/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2615 - acc: 0.9063 - val_loss: 0.6084 - val_acc: 0.8187\n",
      "Epoch 137/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2571 - acc: 0.9076 - val_loss: 0.5949 - val_acc: 0.8247\n",
      "Epoch 138/350\n",
      "50000/50000 [==============================] - 125s - loss: 0.2564 - acc: 0.9076 - val_loss: 0.6084 - val_acc: 0.8151\n",
      "Epoch 139/350\n",
      "50000/50000 [==============================] - 124s - loss: 0.2547 - acc: 0.9084 - val_loss: 0.5791 - val_acc: 0.8269\n",
      "Epoch 140/350\n",
      "50000/50000 [==============================] - 121s - loss: 0.2543 - acc: 0.9089 - val_loss: 0.6112 - val_acc: 0.8187\n",
      "Epoch 141/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2506 - acc: 0.9103 - val_loss: 0.5891 - val_acc: 0.8287\n",
      "Epoch 142/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2462 - acc: 0.9104 - val_loss: 0.5885 - val_acc: 0.8263\n",
      "Epoch 143/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2483 - acc: 0.9109 - val_loss: 0.6054 - val_acc: 0.8188\n",
      "Epoch 144/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2411 - acc: 0.9129 - val_loss: 0.6176 - val_acc: 0.8249\n",
      "Epoch 145/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2395 - acc: 0.9126 - val_loss: 0.6553 - val_acc: 0.8113\n",
      "Epoch 146/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2372 - acc: 0.9147 - val_loss: 0.5978 - val_acc: 0.8210\n",
      "Epoch 147/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2385 - acc: 0.9156 - val_loss: 0.6170 - val_acc: 0.8210\n",
      "Epoch 148/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2367 - acc: 0.9155 - val_loss: 0.6099 - val_acc: 0.8229\n",
      "Epoch 149/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2320 - acc: 0.9155 - val_loss: 0.6002 - val_acc: 0.8264\n",
      "Epoch 150/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2309 - acc: 0.9167 - val_loss: 0.5952 - val_acc: 0.8267\n",
      "Epoch 151/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2247 - acc: 0.9190 - val_loss: 0.6173 - val_acc: 0.8210\n",
      "Epoch 152/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2276 - acc: 0.9169 - val_loss: 0.5910 - val_acc: 0.8297\n",
      "Epoch 153/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2210 - acc: 0.9211 - val_loss: 0.6183 - val_acc: 0.8240\n",
      "Epoch 154/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2228 - acc: 0.9186 - val_loss: 0.6082 - val_acc: 0.8219\n",
      "Epoch 155/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2190 - acc: 0.9210 - val_loss: 0.6236 - val_acc: 0.8235\n",
      "Epoch 156/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2169 - acc: 0.9223 - val_loss: 0.6059 - val_acc: 0.8272\n",
      "Epoch 157/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2147 - acc: 0.9226 - val_loss: 0.6116 - val_acc: 0.8247\n",
      "Epoch 158/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2118 - acc: 0.9237 - val_loss: 0.6231 - val_acc: 0.8214\n",
      "Epoch 159/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2149 - acc: 0.9219 - val_loss: 0.6250 - val_acc: 0.8247\n",
      "Epoch 160/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2084 - acc: 0.9236 - val_loss: 0.6189 - val_acc: 0.8236\n",
      "Epoch 161/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2077 - acc: 0.9249 - val_loss: 0.6344 - val_acc: 0.8232\n",
      "Epoch 162/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2087 - acc: 0.9245 - val_loss: 0.6062 - val_acc: 0.8272\n",
      "Epoch 163/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2025 - acc: 0.9266 - val_loss: 0.6127 - val_acc: 0.8286\n",
      "Epoch 164/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2053 - acc: 0.9253 - val_loss: 0.5968 - val_acc: 0.8299\n",
      "Epoch 165/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2016 - acc: 0.9253 - val_loss: 0.6144 - val_acc: 0.8275\n",
      "Epoch 166/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2024 - acc: 0.9269 - val_loss: 0.6153 - val_acc: 0.8260\n",
      "Epoch 167/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.2010 - acc: 0.9274 - val_loss: 0.6449 - val_acc: 0.8214\n",
      "Epoch 168/350\n",
      "50000/50000 [==============================] - 93s - loss: 0.1943 - acc: 0.9292 - val_loss: 0.6197 - val_acc: 0.8261\n",
      "Epoch 169/350\n",
      "50000/50000 [==============================] - 93s - loss: 0.2004 - acc: 0.9269 - val_loss: 0.6386 - val_acc: 0.8294\n",
      "Epoch 170/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.1950 - acc: 0.9298 - val_loss: 0.6364 - val_acc: 0.8219\n",
      "Epoch 171/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.1921 - acc: 0.9304 - val_loss: 0.6204 - val_acc: 0.8301\n",
      "Epoch 172/350\n",
      "50000/50000 [==============================] - 93s - loss: 0.1892 - acc: 0.9326 - val_loss: 0.6305 - val_acc: 0.8240\n",
      "Epoch 173/350\n",
      "50000/50000 [==============================] - 94s - loss: 0.1893 - acc: 0.9315 - val_loss: 0.6221 - val_acc: 0.8273\n",
      "Epoch 174/350\n",
      "50000/50000 [==============================] - 93s - loss: 0.1863 - acc: 0.9315 - val_loss: 0.6391 - val_acc: 0.8285\n",
      "Epoch 175/350\n",
      " 8704/50000 [====>.........................] - ETA: 73s - loss: 0.1870 - acc: 0.9319"
     ]
    }
   ],
   "source": [
    "model_details = model.fit(images_train, class_train,\n",
    "                    batch_size = 128,\n",
    "                    epochs = NUM_EPOCH, # number of iterations\n",
    "                    validation_data= (images_test, class_test),\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(images_test, class_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model accuracy and loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code augments the dataset to have random shifts, rotations and flips, thus increasing the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_model = pure_cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_checkpoint = ModelCheckpoint('augmented_best_model.h5',  # model filename\n",
    "                             monitor='val_loss', # quantity to monitor\n",
    "                             verbose=0, # verbosity - 0 or 1\n",
    "                             save_best_only= True, # The latest best model will not be overwritten\n",
    "                             mode='auto') # The decision to overwrite model is made \n",
    "                                          # automatically depending on the quantity to monitor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
    "              optimizer=Adam(lr=LEARN_RATE), # Adam optimizer with 1.0e-4 learning rate\n",
    "              metrics = ['accuracy']) # Metrics to be evaluated by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on the data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_model_details = augmented_model.fit_generator(datagen.flow(images_train, class_train, batch_size = 32),\n",
    "                    steps_per_epoch = len(images_train) / 32, # number of samples per gradient update\n",
    "                    epochs = NUM_EPOCH, # number of iterations\n",
    "                    validation_data= (images_test, class_test),\n",
    "                    callbacks=[augmented_checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = augmented_model.evaluate(images_test, class_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model accuracy and loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(augmented_model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve the model, run it for more epochs and do more augmentations like ZCA whitening. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict class for test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct, labels_pred = predict_classes(augmented_model, images_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy using manual calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(correct)\n",
    "print(\"Accuracy: %.2f%%\" % ((sum(correct)*100)/num_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some mis-classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 9 mis-classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_errors(images_test, labels_test, class_names, labels_pred, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    " - https://arxiv.org/pdf/1412.6806.pdf\n",
    " - https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py\n",
    " - https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb\n",
    " - http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\n",
    " - https://parneetk.github.io/blog/cnn-cifar10/\n",
    " - https://github.com/dnlcrl/deep-residual-networks-pyfunt/blob/master/docs/CIFAR-10%20Experiments.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
